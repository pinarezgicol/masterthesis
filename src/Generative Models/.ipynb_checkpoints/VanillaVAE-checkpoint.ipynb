{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdCppuKpdq1x",
    "outputId": "1277a5f7-38e9-43c6-cd9b-2ac12780f7bc"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, Lambda, Layer\n",
    "from keras.regularizers import l2\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import model_from_yaml\n",
    "from modAL.models import ActiveLearner\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.backend import eager_learning_phase_scope\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "(x_tr, y_tr), (x_te, y_te) = mnist.load_data()\n",
    "x_tr, x_te = x_tr.astype('float32')/255., x_te.astype('float32')/255.\n",
    "x_tr, x_te = x_tr.reshape(x_tr.shape[0], -1), x_te.reshape(x_te.shape[0], -1)\n",
    "print(x_tr.shape, x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "ORIGINAL_DIM = 784\n",
    "HIDDEN_DIM = 512\n",
    "EPOCH = 50\n",
    "epsilon_std = 1.0\n",
    "LATENT_DIMS = [2, 4, 8, 16, 32, 64, 128, 256, 512]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output custom_variational_layer missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          401920      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            1026        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            1026        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2)            0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          1536        ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 784)          402192      ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " custom_variational_layer (Cust  (None, 784)         0           ['input_1[0][0]',                \n",
      " omVariationalLayer)                                              'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 807,700\n",
      "Trainable params: 807,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 214.9434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pinar\\onedrive\\masaüstü\\masterthesis\\msthesisenv\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 71us/sample - loss: 214.6102 - val_loss: 180.7904\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 175.1102 - val_loss: 170.7550\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 169.0752 - val_loss: 167.8293\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 166.5508 - val_loss: 166.0203\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 164.8774 - val_loss: 164.6428\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 163.4778 - val_loss: 163.3545\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 162.2277 - val_loss: 162.0198\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 161.0089 - val_loss: 160.7816\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 159.9406 - val_loss: 159.9808\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 159.0111 - val_loss: 159.1758\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 158.1597 - val_loss: 158.4012\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 157.4549 - val_loss: 157.8350\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 156.8798 - val_loss: 157.2642\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 156.3165 - val_loss: 156.9711\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 155.8064 - val_loss: 156.3538\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 155.3469 - val_loss: 156.0236\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 154.8878 - val_loss: 155.7409\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 154.4907 - val_loss: 155.3857\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 154.1384 - val_loss: 155.0570\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 153.7934 - val_loss: 154.7086\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 153.4863 - val_loss: 154.7745\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 153.2109 - val_loss: 154.3751\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 152.9434 - val_loss: 154.1331\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 152.6446 - val_loss: 154.0916\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 152.3859 - val_loss: 153.7449\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 152.1592 - val_loss: 153.7502\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 151.9357 - val_loss: 153.5027\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 151.6752 - val_loss: 153.4432\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 151.4848 - val_loss: 153.2455\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 151.2633 - val_loss: 153.2699\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 151.0977 - val_loss: 153.0644\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 150.8610 - val_loss: 152.7318\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 150.7067 - val_loss: 152.7495\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 150.5164 - val_loss: 152.6106\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 150.3224 - val_loss: 152.5850\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 150.2084 - val_loss: 152.5210\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 150.0113 - val_loss: 152.2047\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 149.8467 - val_loss: 152.1512\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 149.7463 - val_loss: 152.3138\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 149.5896 - val_loss: 152.1258\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 149.4307 - val_loss: 152.2008\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 149.3232 - val_loss: 152.3569\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 149.1728 - val_loss: 152.0862\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 149.0511 - val_loss: 151.8715\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 148.8693 - val_loss: 151.8413\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 148.8226 - val_loss: 151.6824\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 148.6672 - val_loss: 151.6714\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 148.5469 - val_loss: 151.7008\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 148.4689 - val_loss: 151.6310\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 148.3411 - val_loss: 151.5978\n",
      "WARNING:tensorflow:Output custom_variational_layer_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_1.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 512)          401920      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4)            2052        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            2052        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 4)            0           ['dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 512)          2560        ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 784)          402192      ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " custom_variational_layer_1 (Cu  (None, 784)         0           ['input_2[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 810,776\n",
      "Trainable params: 810,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 67us/sample - loss: 201.6998 - val_loss: 160.3322\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 154.2113 - val_loss: 148.6118\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 146.7072 - val_loss: 144.2037\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 143.4589 - val_loss: 141.4288\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 141.3029 - val_loss: 139.7475\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 139.8271 - val_loss: 138.8098\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 138.6244 - val_loss: 137.6526\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 137.6103 - val_loss: 136.6626\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 136.7415 - val_loss: 135.9040\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 135.9319 - val_loss: 135.3340\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 135.2094 - val_loss: 134.6428\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 134.5668 - val_loss: 134.0999\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 133.9693 - val_loss: 133.6302\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 133.4204 - val_loss: 133.1463\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 132.8963 - val_loss: 132.6662\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 132.4444 - val_loss: 132.2701\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 132.0177 - val_loss: 131.8679\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 131.5674 - val_loss: 131.6707\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 131.1950 - val_loss: 131.2859\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 130.8320 - val_loss: 131.0917\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 130.5142 - val_loss: 130.6097\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 130.1930 - val_loss: 130.4783\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 129.9035 - val_loss: 130.2018\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 129.5962 - val_loss: 129.9632\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 129.3367 - val_loss: 129.8610\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 129.0519 - val_loss: 129.6097\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 128.7919 - val_loss: 129.6033\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 128.5589 - val_loss: 129.1840\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 128.3503 - val_loss: 129.0181\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 128.1790 - val_loss: 128.9595\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 127.9443 - val_loss: 128.7870\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 127.7494 - val_loss: 128.6477\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 127.5600 - val_loss: 128.4453\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 127.3862 - val_loss: 128.5260\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 127.2039 - val_loss: 128.4040\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 127.0521 - val_loss: 128.1874\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 126.9009 - val_loss: 128.0583\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 126.7654 - val_loss: 128.0490\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 126.6012 - val_loss: 128.0563\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 126.4875 - val_loss: 127.6694\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 126.3039 - val_loss: 128.0146\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 126.2315 - val_loss: 127.5543\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 126.0739 - val_loss: 127.6356\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 125.9461 - val_loss: 127.4778\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 125.8668 - val_loss: 127.5141\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 125.7260 - val_loss: 127.2542\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 125.5785 - val_loss: 127.3383\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 125.4699 - val_loss: 127.1918\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 125.3906 - val_loss: 127.2726\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 125.2952 - val_loss: 127.1917\n",
      "WARNING:tensorflow:Output custom_variational_layer_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_2.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 512)          401920      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 8)            4104        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 8)            4104        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 8)            0           ['dense_11[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 512)          4608        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 784)          402192      ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer_2 (Cu  (None, 784)         0           ['input_3[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 816,928\n",
      "Trainable params: 816,928\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 82us/sample - loss: 188.7268 - val_loss: 145.2140\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 138.8302 - val_loss: 132.6125\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 130.4316 - val_loss: 126.9696\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 126.2600 - val_loss: 124.0913\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 123.7358 - val_loss: 122.2472\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 122.0316 - val_loss: 120.6086\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 120.6947 - val_loss: 119.3279\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 119.6660 - val_loss: 118.4953\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 118.7316 - val_loss: 117.6755\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 117.9476 - val_loss: 116.9209\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 117.2987 - val_loss: 116.2247\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 116.6474 - val_loss: 115.7809\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 116.1179 - val_loss: 115.2425\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 115.5813 - val_loss: 114.8188\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 115.0529 - val_loss: 114.2738\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 114.6102 - val_loss: 113.8042\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 114.1395 - val_loss: 113.4859\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 113.7583 - val_loss: 113.0694\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 113.3601 - val_loss: 112.9156\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 113.0063 - val_loss: 112.5172\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 112.6617 - val_loss: 112.3415\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 112.3492 - val_loss: 111.8917\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 112.0702 - val_loss: 111.8726\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 111.7995 - val_loss: 111.4597\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 111.4814 - val_loss: 111.2962\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 111.2578 - val_loss: 111.1779\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 110.9912 - val_loss: 110.8435\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 110.7829 - val_loss: 110.6879\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 110.5714 - val_loss: 110.5463\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 110.3562 - val_loss: 110.3838\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 110.1684 - val_loss: 110.1298\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 109.9972 - val_loss: 110.0368\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 109.8161 - val_loss: 110.1250\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 109.6753 - val_loss: 109.8328\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 109.4961 - val_loss: 109.6918\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 109.3318 - val_loss: 109.5760\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 109.1990 - val_loss: 109.4785\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 109.0736 - val_loss: 109.3189\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 108.9617 - val_loss: 109.1882\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 108.7957 - val_loss: 109.1398\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 108.7114 - val_loss: 109.0439\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 108.5965 - val_loss: 109.0567\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 108.4424 - val_loss: 108.8987\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 108.3261 - val_loss: 108.8943\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 108.2382 - val_loss: 108.8243\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 108.1633 - val_loss: 108.8480\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 108.0600 - val_loss: 108.7249\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 108.0135 - val_loss: 108.6588\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 107.8697 - val_loss: 108.6053\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 107.7886 - val_loss: 108.4779\n",
      "WARNING:tensorflow:Output custom_variational_layer_3 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_3.\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 512)          401920      ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 16)           8208        ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 16)           8208        ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 16)           0           ['dense_16[0][0]',               \n",
      "                                                                  'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 512)          8704        ['lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 784)          402192      ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer_3 (Cu  (None, 784)         0           ['input_4[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 829,232\n",
      "Trainable params: 829,232\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 68us/sample - loss: 183.2727 - val_loss: 137.8741\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 129.3965 - val_loss: 122.2396\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 120.7862 - val_loss: 117.2870\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 116.7262 - val_loss: 114.2972\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 114.0795 - val_loss: 112.3957\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 112.2950 - val_loss: 110.7261\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 110.9294 - val_loss: 109.4677\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 109.8495 - val_loss: 108.6109\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 109.0963 - val_loss: 108.0860\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 108.3832 - val_loss: 107.4469\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 107.8480 - val_loss: 106.9713\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 107.3517 - val_loss: 106.6467\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 106.9399 - val_loss: 106.4160\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 106.6115 - val_loss: 106.0938\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 106.2593 - val_loss: 105.6796\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 105.9334 - val_loss: 105.4241\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 105.6938 - val_loss: 105.2003\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 105.4400 - val_loss: 104.9472\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 105.1557 - val_loss: 104.8165\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 104.9640 - val_loss: 104.8132\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 104.7746 - val_loss: 104.5911\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 104.6222 - val_loss: 104.3785\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 104.4396 - val_loss: 104.2260\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 104.2721 - val_loss: 104.0386\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 104.0852 - val_loss: 104.0252\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 103.9614 - val_loss: 103.7858\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 103.7810 - val_loss: 103.6254\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 103.6806 - val_loss: 103.6359\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 103.5811 - val_loss: 103.5195\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 103.4532 - val_loss: 103.4299\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 103.2886 - val_loss: 103.3050\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 103.1901 - val_loss: 103.3400\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 103.0777 - val_loss: 103.1389\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.9951 - val_loss: 103.0335\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 102.8719 - val_loss: 102.9347\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.7887 - val_loss: 102.9620\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.6636 - val_loss: 102.6952\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.6247 - val_loss: 102.7314\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.5476 - val_loss: 102.6793\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.4263 - val_loss: 102.5822\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.3749 - val_loss: 102.5216\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 102.3056 - val_loss: 102.6296\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.1955 - val_loss: 102.3907\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.1448 - val_loss: 102.4936\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 102.0527 - val_loss: 102.2751\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 101.9737 - val_loss: 102.3502\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 101.9505 - val_loss: 102.3685\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 101.8463 - val_loss: 102.1479\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 101.8148 - val_loss: 102.1923\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 101.7224 - val_loss: 102.0464\n",
      "WARNING:tensorflow:Output custom_variational_layer_4 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_4.\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 512)          401920      ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 32)           16416       ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 32)           16416       ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 32)           0           ['dense_21[0][0]',               \n",
      "                                                                  'dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 512)          16896       ['lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 784)          402192      ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer_4 (Cu  (None, 784)         0           ['input_5[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_24[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 853,840\n",
      "Trainable params: 853,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 71us/sample - loss: 182.3782 - val_loss: 139.3840\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 130.4165 - val_loss: 122.6880\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 120.2178 - val_loss: 116.3172\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 115.7076 - val_loss: 113.0926\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 113.0469 - val_loss: 111.0495\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 111.2027 - val_loss: 109.6209\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 109.8026 - val_loss: 108.3897\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 108.8059 - val_loss: 107.8620\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 107.9912 - val_loss: 107.1353\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 107.3525 - val_loss: 106.5502\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 106.7859 - val_loss: 106.1336\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 106.3448 - val_loss: 105.8081\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 105.9401 - val_loss: 105.2316\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 105.6235 - val_loss: 105.1856\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 105.3082 - val_loss: 104.7269\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 105.0203 - val_loss: 104.4768\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 104.8045 - val_loss: 104.2416\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 104.6171 - val_loss: 104.3441\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 104.3662 - val_loss: 104.0251\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 104.2353 - val_loss: 103.8659\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 104.0123 - val_loss: 103.7915\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 103.8833 - val_loss: 103.6163\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 103.7889 - val_loss: 103.5983\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 103.6487 - val_loss: 103.5448\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 103.5086 - val_loss: 103.2053\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 103.3784 - val_loss: 103.2613\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 103.2847 - val_loss: 102.9972\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 103.1552 - val_loss: 102.8919\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 103.0583 - val_loss: 103.0923\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 103.0222 - val_loss: 102.8279\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 102.8872 - val_loss: 102.7942\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 102.8175 - val_loss: 102.5891\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 102.7170 - val_loss: 102.6470\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 102.6418 - val_loss: 102.5789\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 102.5204 - val_loss: 102.5909\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 102.5229 - val_loss: 102.4331\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 102.4048 - val_loss: 102.4796\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 102.3452 - val_loss: 102.3505\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 102.2741 - val_loss: 102.0824\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 102.2038 - val_loss: 102.1112\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 102.1462 - val_loss: 102.2375\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 102.1092 - val_loss: 101.9851\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 102.0612 - val_loss: 102.1905\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 101.9525 - val_loss: 101.9274\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 101.8875 - val_loss: 101.8465\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 101.8301 - val_loss: 101.9720\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 101.8274 - val_loss: 101.9548\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 101.7202 - val_loss: 101.8558\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 101.7370 - val_loss: 101.8714\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 101.6971 - val_loss: 101.8304\n",
      "WARNING:tensorflow:Output custom_variational_layer_5 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_5.\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 512)          401920      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 64)           32832       ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 64)           32832       ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 64)           0           ['dense_26[0][0]',               \n",
      "                                                                  'dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 512)          33280       ['lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 784)          402192      ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer_5 (Cu  (None, 784)         0           ['input_6[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_29[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 903,056\n",
      "Trainable params: 903,056\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 76us/sample - loss: 184.6625 - val_loss: 143.2726\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 135.1769 - val_loss: 126.9559\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 123.7606 - val_loss: 119.2739\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 117.7507 - val_loss: 114.5350\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 114.1870 - val_loss: 111.9570\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 111.8468 - val_loss: 110.3140\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 110.3215 - val_loss: 108.7563\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 109.1928 - val_loss: 107.9854\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 108.2940 - val_loss: 107.5121\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 107.6034 - val_loss: 106.7350\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 107.0235 - val_loss: 106.2942\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 106.5361 - val_loss: 106.0034\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 106.0951 - val_loss: 105.7034\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 105.7650 - val_loss: 105.1487\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 105.4939 - val_loss: 104.9710\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 105.2011 - val_loss: 104.8924\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 105.0226 - val_loss: 104.4096\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 104.7735 - val_loss: 104.3928\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 104.5747 - val_loss: 104.5516\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 104.4616 - val_loss: 104.0388\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 104.2419 - val_loss: 104.0256\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 104.0852 - val_loss: 103.8093\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.8988 - val_loss: 103.9618\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.8307 - val_loss: 103.5758\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.6781 - val_loss: 103.4602\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.5293 - val_loss: 103.4951\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.4475 - val_loss: 103.3577\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.3838 - val_loss: 103.1152\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.1764 - val_loss: 103.1135\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.1016 - val_loss: 103.1399\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 103.0554 - val_loss: 102.9008\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 103.0183 - val_loss: 102.8007\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.8996 - val_loss: 102.7608\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.7775 - val_loss: 102.7313\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.7053 - val_loss: 102.6254\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.6653 - val_loss: 102.7181\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.6476 - val_loss: 102.4799\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.5534 - val_loss: 102.6098\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 102.4499 - val_loss: 102.5357\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.4071 - val_loss: 102.5678\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.2989 - val_loss: 102.4069\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.2722 - val_loss: 102.4306\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.1934 - val_loss: 102.3792\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.1627 - val_loss: 102.4130\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.1318 - val_loss: 102.3547\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 102.0221 - val_loss: 102.1610\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 102.0175 - val_loss: 102.0402\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 101.9668 - val_loss: 102.0188\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 101.8945 - val_loss: 102.0009\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 101.8665 - val_loss: 102.1339\n",
      "WARNING:tensorflow:Output custom_variational_layer_6 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_6.\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 512)          401920      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 128)          65664       ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          65664       ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 128)          0           ['dense_31[0][0]',               \n",
      "                                                                  'dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 512)          66048       ['lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 784)          402192      ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer_6 (Cu  (None, 784)         0           ['input_7[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_34[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,001,488\n",
      "Trainable params: 1,001,488\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 80us/sample - loss: 186.6401 - val_loss: 147.2900\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 140.0590 - val_loss: 132.8274\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 128.5384 - val_loss: 123.0611\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 120.8938 - val_loss: 117.4660\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 116.3233 - val_loss: 113.8008\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 113.3936 - val_loss: 111.3774\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 111.4267 - val_loss: 110.0382\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 110.1161 - val_loss: 108.9683\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 109.0720 - val_loss: 108.1171\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 108.2797 - val_loss: 107.5653\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 107.6114 - val_loss: 106.9246\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 107.1243 - val_loss: 106.3075\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 106.5897 - val_loss: 105.9718\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 106.1773 - val_loss: 105.6661\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 105.8658 - val_loss: 105.3146\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 105.5597 - val_loss: 105.0236\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 105.2662 - val_loss: 104.7521\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 105.0492 - val_loss: 104.6827\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 104.8100 - val_loss: 104.3194\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 104.5885 - val_loss: 104.2310\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 104.4902 - val_loss: 104.3111\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 104.2983 - val_loss: 104.0192\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 104.1292 - val_loss: 103.9628\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 104.0023 - val_loss: 103.8134\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 103.8339 - val_loss: 103.6410\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 103.7359 - val_loss: 103.5356\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 103.6090 - val_loss: 103.3119\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 103.4452 - val_loss: 103.2187\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 103.3429 - val_loss: 103.1329\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 103.2461 - val_loss: 103.1997\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 103.1604 - val_loss: 103.0437\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 103.1165 - val_loss: 103.0266\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 102.9845 - val_loss: 102.9494\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.9217 - val_loss: 102.8311\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 102.8579 - val_loss: 103.0982\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.7245 - val_loss: 102.8386\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.6705 - val_loss: 102.6026\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 102.5249 - val_loss: 102.4487\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.5175 - val_loss: 102.5473\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 102.4160 - val_loss: 102.4255\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.3506 - val_loss: 102.4605\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 102.3006 - val_loss: 102.2958\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.2285 - val_loss: 102.1702\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.1645 - val_loss: 102.2553\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 102.1364 - val_loss: 102.2828\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 102.0351 - val_loss: 102.0579\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 102.0076 - val_loss: 102.2907\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 101.9862 - val_loss: 102.1013\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 101.9568 - val_loss: 101.9975\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 101.8386 - val_loss: 102.2212\n",
      "WARNING:tensorflow:Output custom_variational_layer_7 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_7.\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 512)          401920      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 256)          131328      ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 256)          131328      ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 256)          0           ['dense_36[0][0]',               \n",
      "                                                                  'dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 512)          131584      ['lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 784)          402192      ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer_7 (Cu  (None, 784)         0           ['input_8[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_39[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,198,352\n",
      "Trainable params: 1,198,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 98us/sample - loss: 189.2883 - val_loss: 151.2990\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 145.7809 - val_loss: 140.3099\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 138.2949 - val_loss: 134.3922\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 132.4621 - val_loss: 128.4016\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 126.3331 - val_loss: 122.2791\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 120.6119 - val_loss: 117.2297\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 116.4461 - val_loss: 114.0632\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 113.7749 - val_loss: 111.8462\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 111.7955 - val_loss: 110.2674\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 110.4848 - val_loss: 109.4435\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 109.4570 - val_loss: 108.4320\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 108.6721 - val_loss: 107.8606\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 108.0717 - val_loss: 107.6786\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 107.5235 - val_loss: 106.9102\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 107.0919 - val_loss: 106.5134\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 106.7173 - val_loss: 106.1776\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 106.3693 - val_loss: 105.9731\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 106.0888 - val_loss: 105.5518\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 105.8430 - val_loss: 105.4837\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 105.5801 - val_loss: 104.9723\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 105.3946 - val_loss: 105.3238\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 105.2193 - val_loss: 104.9483\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 104.9712 - val_loss: 104.6622\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 104.8984 - val_loss: 104.5549\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 104.7628 - val_loss: 104.5589\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 104.5684 - val_loss: 104.5343\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 104.4641 - val_loss: 104.2247\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 104.3156 - val_loss: 104.2237\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 104.2761 - val_loss: 104.0738\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 104.1152 - val_loss: 103.9727\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 103.9697 - val_loss: 103.8699\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 103.9218 - val_loss: 103.8505\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 103.7784 - val_loss: 103.7356\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 103.7486 - val_loss: 103.8372\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 103.6114 - val_loss: 103.5527\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 103.5256 - val_loss: 103.4777\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 103.4661 - val_loss: 103.5135\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 103.3716 - val_loss: 103.2789\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 103.3116 - val_loss: 103.3916\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 103.1925 - val_loss: 103.3274\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 103.1436 - val_loss: 103.1186\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 103.0760 - val_loss: 102.9624\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 103.0055 - val_loss: 103.0814\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 102.9988 - val_loss: 103.0011\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 102.8947 - val_loss: 103.0337\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 102.8056 - val_loss: 102.8464\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 102.7246 - val_loss: 102.6900\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 102.6925 - val_loss: 102.8803\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 102.6422 - val_loss: 102.6552\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 102.6018 - val_loss: 102.6187\n",
      "WARNING:tensorflow:Output custom_variational_layer_8 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_8.\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 512)          401920      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 512)          262656      ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 512)          262656      ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 512)          0           ['dense_41[0][0]',               \n",
      "                                                                  'dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 512)          262656      ['lambda_8[0][0]']               \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 784)          402192      ['dense_43[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer_8 (Cu  (None, 784)         0           ['input_9[0][0]',                \n",
      " stomVariationalLayer)                                            'dense_44[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,592,080\n",
      "Trainable params: 1,592,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 8s 137us/sample - loss: 191.0157 - val_loss: 154.0742\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 148.4656 - val_loss: 143.4874\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 141.4903 - val_loss: 139.0264\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 138.1920 - val_loss: 135.8269\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 135.6516 - val_loss: 133.1717\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 132.3189 - val_loss: 129.2282\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 128.3653 - val_loss: 125.5661\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 124.3577 - val_loss: 121.5401\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 120.6266 - val_loss: 118.1889\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 117.3513 - val_loss: 115.1556\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 114.8252 - val_loss: 113.0322\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 112.8883 - val_loss: 111.2737\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 111.3161 - val_loss: 109.9166\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 110.0708 - val_loss: 108.8873\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 109.1870 - val_loss: 108.1041\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 108.4527 - val_loss: 107.7424\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 107.9341 - val_loss: 107.0897\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 107.4780 - val_loss: 106.7307\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 107.0817 - val_loss: 106.4269\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 106.7296 - val_loss: 106.1144\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 106.4645 - val_loss: 106.2734\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 106.2150 - val_loss: 105.6204\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 105.9728 - val_loss: 105.4404\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 105.7525 - val_loss: 105.4171\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 105.5639 - val_loss: 105.3186\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 105.3816 - val_loss: 105.2090\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 105.2789 - val_loss: 105.0068\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 105.1259 - val_loss: 104.7543\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 104.9973 - val_loss: 104.8520\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 104.8577 - val_loss: 104.6027\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 104.7160 - val_loss: 104.6200\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 104.6041 - val_loss: 104.4429\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 104.5132 - val_loss: 104.3382\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 104.4023 - val_loss: 104.1952\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 104.3292 - val_loss: 104.1224\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 104.1728 - val_loss: 104.1238\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 104.0800 - val_loss: 103.9653\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 104.0112 - val_loss: 103.7853\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 103.9618 - val_loss: 103.9604\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.8909 - val_loss: 103.8421\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.8021 - val_loss: 103.6738\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.7599 - val_loss: 103.5662\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.6419 - val_loss: 103.5399\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.5338 - val_loss: 103.5181\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.5029 - val_loss: 103.4794\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.4683 - val_loss: 103.2688\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 103.3470 - val_loss: 103.3366\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 103.2919 - val_loss: 103.3816\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 103.2524 - val_loss: 103.2315\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 103.1845 - val_loss: 103.0517\n"
     ]
    }
   ],
   "source": [
    "# encoder architecture\n",
    "for latent_dim in LATENT_DIMS:\n",
    "    x = Input(shape=(ORIGINAL_DIM,))\n",
    "    encoder_h = Dense(HIDDEN_DIM, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim)(encoder_h)\n",
    "    z_log_var = Dense(latent_dim)(encoder_h)\n",
    "\n",
    "    # sampling layer from latent distribution\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    #z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "    # decoder / generator architecture\n",
    "    decoder_h = Dense(HIDDEN_DIM, activation='relu')\n",
    "    decoder_mean = Dense(ORIGINAL_DIM, activation='sigmoid')\n",
    "    h_decoded = decoder_h(z)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "    # Custom loss layer\n",
    "    class CustomVariationalLayer(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            self.is_placeholder = True\n",
    "            super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def vae_loss(self, x, x_decoded_mean):\n",
    "            xent_loss = ORIGINAL_DIM * keras.metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "            kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "            return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            x = inputs[0]\n",
    "            x_decoded_mean = inputs[1]\n",
    "            loss = self.vae_loss(x, x_decoded_mean)\n",
    "            self.add_loss(loss, inputs=inputs)\n",
    "            # We won't actually use the output.\n",
    "            return x\n",
    "\n",
    "    y = CustomVariationalLayer()([x, x_decoded_mean])\n",
    "\n",
    "    # entire model\n",
    "    vae = Model(x, y)\n",
    "    vae.compile(optimizer='adam', loss=None)\n",
    "    vae.summary()\n",
    "    \n",
    "    # training\n",
    "    \n",
    "    history = vae.fit(x_tr,\n",
    "            shuffle=True,\n",
    "            epochs=EPOCH,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(x_te, None))\n",
    "    \n",
    "    # build encoder\n",
    "    encoder = Model(x, z_mean)\n",
    "    \n",
    "    encoder.save(\"mnist_vanillavae_z_mean_{latent_dim}.h5\".format(latent_dim=latent_dim))\n",
    "    \n",
    "    encoder = Model(x, z)\n",
    "    \n",
    "    encoder.save(\"mnist_vanillavae_z_{latent_dim}.h5\".format(latent_dim=latent_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.manifold import TSNE \n",
    "import seaborn as sb\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "#With the above line, our job is done. But why did we even reduce the dimensions in the first place?\n",
    "#To visualise it on a graph.\n",
    "\n",
    "#So, here is a utility function that helps to do a scatter plot of thee transformed data \n",
    "\n",
    "def plot(x, colors):\n",
    "  \n",
    "    palette = np.array(sb.color_palette(\"hls\", 10))  #Choosing color palette \n",
    "\n",
    "    # Create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "    # Add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(10):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([pe.Stroke(linewidth=5, foreground=\"w\"), pe.Normal()])\n",
    "        txts.append(txt)\n",
    "    return f, ax, txts\n",
    "\n",
    "# Plot of the digit classes in the latent space\n",
    "x_te_latent = encoder.predict(x_te, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_te_latent[:, 0], x_te_latent[:, 1], c=y_te)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "digits_final = TSNE(perplexity=30).fit_transform(x_te_latent) \n",
    "\n",
    "plot(digits_final,y_te)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dbal_keras_different_latent_sizes.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "msthesisenv",
   "language": "python",
   "name": "msthesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
