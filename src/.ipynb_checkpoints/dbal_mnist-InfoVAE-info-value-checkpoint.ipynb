{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import MNIST\n",
    "from skorch import NeuralNetClassifier\n",
    "from modAL.models import ActiveLearner\n",
    "from batchbald_redux import batchbald\n",
    "from acquisition_functions import *\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIMS = [64]\n",
    "LATENT_DIM = 64\n",
    "MAX_EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "EXPERIMENT_COUNT = 1\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 512\n",
    "ORIGINAL_DIM = 784\n",
    "results_path = 'results\\\\mnist_infovae_dbal'\n",
    "epsilon_std = 1.0\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "ACQ_FUNCS = {\n",
    "    \"bald\": bald_info_value_infovae,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_REG(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(MLP_REG, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 10),)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1).astype('float32') / 255.\n",
    "X_test = X_test.reshape(10000, 28, 28, 1).astype('float32') / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enhanced = np.load(r\"C:\\Users\\pinar\\OneDrive\\Masa端st端\\masterthesis\\src\\Generative Models\\mnist\\x_train_enhanced_infovae.npy\")\n",
    "X_test_enhanced = np.load(r\"C:\\Users\\pinar\\OneDrive\\Masa端st端\\masterthesis\\src\\Generative Models\\mnist\\x_test_enhanced_infovae.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning_procedure(query_strategy,\n",
    "                              X_test,\n",
    "                              y_test,\n",
    "                              X_pool,\n",
    "                              y_pool,\n",
    "                              X_initial,\n",
    "                              y_initial,\n",
    "                              estimator,\n",
    "                              n_queries=98,\n",
    "                              n_instances=10):\n",
    "    learner = ActiveLearner(estimator=estimator,\n",
    "                            X_training=X_initial,\n",
    "                            y_training=y_initial,\n",
    "                            query_strategy=query_strategy,\n",
    "                           )\n",
    "    perf_hist = [learner.score(X_test, y_test)]\n",
    "    active_pool_size = [len(X_initial)]\n",
    "    pool_size = len(X_initial)\n",
    "    for index in range(n_queries):\n",
    "        query_idx, query_instance = learner.query(X_pool, n_instances)\n",
    "        learner.teach(X_pool[query_idx], y_pool[query_idx])\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "        model_accuracy = learner.score(X_test, y_test)\n",
    "        pool_size = pool_size + n_instances\n",
    "        print('Accuracy after query {n}: {acc:0.4f}'.format(n=index + 1, acc=model_accuracy))\n",
    "        perf_hist.append(model_accuracy)\n",
    "        active_pool_size.append(pool_size)\n",
    "    return perf_hist, active_pool_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent_dim in LATENT_DIMS:\n",
    "    for exp_iter in range(EXPERIMENT_COUNT):\n",
    "        np.random.seed(exp_iter)\n",
    "        initial_idx = np.array([],dtype=int)\n",
    "        for i in range(10):\n",
    "            idx = np.random.choice(np.where(y_train==i)[0], size=2, replace=False)\n",
    "            initial_idx = np.concatenate((initial_idx, idx))\n",
    "\n",
    "        for func_name, acquisition_func in ACQ_FUNCS.items():  \n",
    "\n",
    "            X_initial = X_train_enhanced[initial_idx]\n",
    "            y_initial = y_train[initial_idx]\n",
    "\n",
    "            X_pool = np.delete(X_train_enhanced, initial_idx, axis=0)\n",
    "            y_pool = np.delete(y_train, initial_idx, axis=0)\n",
    "\n",
    "            model = MLP_REG(latent_dim).to(DEVICE)\n",
    "\n",
    "            estimator = NeuralNetClassifier(model,\n",
    "                                          max_epochs=MAX_EPOCHS,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          lr=LEARNING_RATE,\n",
    "                                          optimizer=torch.optim.Adam,\n",
    "                                          criterion=torch.nn.CrossEntropyLoss,\n",
    "                                          train_split=None,\n",
    "                                          verbose=0,\n",
    "                                          device=DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "            acc_arr, dataset_size_arr = active_learning_procedure(acquisition_func,\n",
    "                                                              X_test_enhanced,\n",
    "                                                              y_test,\n",
    "                                                              X_pool,\n",
    "                                                              y_pool,\n",
    "                                                              X_initial,\n",
    "                                                              y_initial,\n",
    "                                                              estimator,)\n",
    "            file_name = os.path.join(results_path, \"{func_name}_latent_dim_{latent_dim}_exp_{exp_iter}.npy\".format(func_name=func_name, exp_iter=exp_iter, latent_dim=latent_dim))\n",
    "            np.save(file_name, (acc_arr, dataset_size_arr))\n",
    "        '''\n",
    "        for func_name, acquisition_func in ACQ_FUNCS.items():  \n",
    "            X_initial = X_train[initial_idx]\n",
    "            y_initial = y_train[initial_idx]\n",
    "\n",
    "            X_pool = np.delete(X_train, initial_idx, axis=0)\n",
    "            y_pool = np.delete(y_train, initial_idx, axis=0)\n",
    "\n",
    "            model = MLP_REG(ORIGINAL_DIM).to(DEVICE)\n",
    "\n",
    "            estimator = NeuralNetClassifier(model,\n",
    "                                          max_epochs=MAX_EPOCHS,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          lr=LEARNING_RATE,\n",
    "                                          optimizer=torch.optim.Adam,\n",
    "                                          criterion=torch.nn.CrossEntropyLoss,\n",
    "                                          train_split=None,\n",
    "                                          verbose=0,\n",
    "                                          device=DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "            acc_arr, dataset_size_arr = active_learning_procedure(acquisition_func,\n",
    "                                                              X_test,\n",
    "                                                              y_test,\n",
    "                                                              X_pool,\n",
    "                                                              y_pool,\n",
    "                                                              X_initial,\n",
    "                                                              y_initial,\n",
    "                                                              estimator,)\n",
    "            file_name = os.path.join(\"results\\\\mnist_dbal\", \"{func_name}_exp_{exp_iter}.npy\".format(func_name=func_name, exp_iter=exp_iter))\n",
    "            np.save(file_name, (acc_arr, dataset_size_arr))\n",
    "        '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msthesisenv",
   "language": "python",
   "name": "msthesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
